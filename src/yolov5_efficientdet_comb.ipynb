{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4060b500",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, cv2, torch\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.font_manager as fm\n",
    "# YOLOv5\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# EfficientDet\n",
    "from effdet import get_efficientdet_config, EfficientDet, DetBenchTrain, DetBenchPredict\n",
    "\n",
    "# COCO API\n",
    "try:\n",
    "    from pycocotools.coco import COCO\n",
    "    from pycocotools.cocoeval import COCOeval\n",
    "    COCO_AVAILABLE = True\n",
    "except ImportError:\n",
    "    print(\"pycocotools 없음\")\n",
    "    COCO_AVAILABLE = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9af46dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 경로 설정\n",
    "BASE_DIR = Path.cwd().parent\n",
    "IMG_DIR = BASE_DIR / \"data/raw/images\"\n",
    "JSON_DIR = BASE_DIR / \"data/raw/json_labels\"\n",
    "DATASET_YOLO = BASE_DIR / \"processed/preprocessed_data/yolov5\"\n",
    "DATASET_EFFDET = BASE_DIR / \"processed/preprocessed_data/efficientdet\"\n",
    "RESULT_DIR = BASE_DIR / \"processed/results_comparison\"\n",
    "YOLO_WEIGHTS_FILE = RESULT_DIR / \"yolov5su.pt\"\n",
    "\n",
    "for d in [DATASET_YOLO, DATASET_EFFDET, RESULT_DIR]:\n",
    "    d.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e7624dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "한글 폰트 설정 완료\n"
     ]
    }
   ],
   "source": [
    "# 한국어 폰트\n",
    "def setup_korean_font():\n",
    "    try:\n",
    "        if os.name == 'nt':\n",
    "            font_path = 'C:/Windows/Fonts/malgun.ttf'\n",
    "            if os.path.exists(font_path):\n",
    "                font_name = fm.FontProperties(fname=font_path).get_name()\n",
    "                plt.rc('font', family=font_name)\n",
    "            else:\n",
    "                plt.rc('font', family='DejaVu Sans')\n",
    "        elif os.name == 'posix':\n",
    "            plt.rc('font', family='AppleGothic')\n",
    "        \n",
    "        plt.rcParams['axes.unicode_minus'] = False\n",
    "        print(\"한글 폰트 설정 완료\")\n",
    "    except Exception as e:\n",
    "        print(f\"폰트 설정 실패: {e}\")\n",
    "        plt.rc('font', family='DejaVu Sans')\n",
    "\n",
    "setup_korean_font()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37675506",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 전처리\n",
    "def preprocess_data():\n",
    "    jsons = list(JSON_DIR.glob(\"*.json\"))\n",
    "    if not jsons:\n",
    "        return {}, []\n",
    "    \n",
    "    train, temp = train_test_split(jsons, train_size=0.8, random_state=42)\n",
    "    val, test = train_test_split(temp, train_size=0.5, random_state=42)\n",
    "    splits = {'train': [], 'val': [], 'test': []}\n",
    "    classes, class_to_idx = [], {}\n",
    "    \n",
    "    for split, files in zip(['train', 'val', 'test'], [train, val, test]):\n",
    "        for j in tqdm(files, desc=f\"Loading {split}\"):\n",
    "            with open(j, 'r', encoding='utf-8') as f:\n",
    "                d = json.load(f)\n",
    "            \n",
    "            # 이미지 찾기\n",
    "            img_path = None\n",
    "            for ext in ['.jpg', '.png', '.jpeg', '.JPG', '.PNG', '.JPEG']:\n",
    "                p = IMG_DIR / f\"{j.stem}{ext}\"\n",
    "                if p.exists():\n",
    "                    img_path = str(p)\n",
    "                    break\n",
    "            if not img_path:\n",
    "                continue\n",
    "            \n",
    "            # 클래스\n",
    "            name = f\"{d['cate1']}_{d['cate3']}\"\n",
    "            if name not in classes:\n",
    "                class_to_idx[name] = len(classes)\n",
    "                classes.append(name)\n",
    "            \n",
    "            bbox = d['bndbox']\n",
    "            splits[split].append({\n",
    "                'image': img_path,\n",
    "                'bbox': [bbox['xmin'], bbox['ymin'], bbox['xmax'], bbox['ymax']],\n",
    "                'label': class_to_idx[name],\n",
    "                'json_stem': j.stem\n",
    "            })\n",
    "    \n",
    "    print(f\"Dataset: train={len(splits['train'])}, val={len(splits['val'])}, test={len(splits['test'])}\")\n",
    "    return splits, classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e63cf84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOLO datasets\n",
    "def prepare_yolo_dataset(splits, classes):\n",
    "    import yaml\n",
    "    \n",
    "    for split in ['train', 'val', 'test']:\n",
    "        (DATASET_YOLO / 'images' / split).mkdir(parents=True, exist_ok=True)\n",
    "        (DATASET_YOLO / 'labels' / split).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    for split, items in splits.items():\n",
    "        for item in tqdm(items, desc=f\"YOLO {split}\"):\n",
    "            with open(item['image'], 'rb') as f:\n",
    "                img = cv2.imdecode(np.frombuffer(f.read(), np.uint8), cv2.IMREAD_COLOR)\n",
    "            h, w = img.shape[:2]\n",
    "            \n",
    "            img_save = DATASET_YOLO / 'images' / split / f\"{item['json_stem']}.jpg\"\n",
    "            cv2.imwrite(str(img_save), img)\n",
    "            \n",
    "            bbox = item['bbox']\n",
    "            x_center = (bbox[0] + bbox[2]) / 2 / w\n",
    "            y_center = (bbox[1] + bbox[3]) / 2 / h\n",
    "            width = (bbox[2] - bbox[0]) / w\n",
    "            height = (bbox[3] - bbox[1]) / h\n",
    "            \n",
    "            label_save = DATASET_YOLO / 'labels' / split / f\"{item['json_stem']}.txt\"\n",
    "            with open(label_save, 'w') as f:\n",
    "                f.write(f\"{item['label']} {x_center:.6f} {y_center:.6f} {width:.6f} {height:.6f}\\n\")\n",
    "    \n",
    "    with open(DATASET_YOLO / 'data.yaml', 'w', encoding='utf-8') as f:\n",
    "        yaml.dump({\n",
    "            'path': str(DATASET_YOLO),\n",
    "            'train': 'images/train',\n",
    "            'val': 'images/val',\n",
    "            'test': 'images/test',\n",
    "            'nc': len(classes),\n",
    "            'names': classes\n",
    "        }, f, allow_unicode=True)\n",
    "    \n",
    "    print(f\"YOLO 데이터셋 준비 완료: {DATASET_YOLO}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f03bd857",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EfficientDet 데이터셋\n",
    "class EffDetDataset(Dataset):\n",
    "    def __init__(self, data, img_size=512):\n",
    "        self.data = data\n",
    "        self.img_size = img_size\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data[idx]\n",
    "        \n",
    "        with open(item['image'], 'rb') as f:\n",
    "            img = cv2.imdecode(np.frombuffer(f.read(), np.uint8), cv2.IMREAD_COLOR)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        h, w = img.shape[:2]\n",
    "        \n",
    "        img = cv2.resize(img, (self.img_size, self.img_size))\n",
    "        img_tensor = torch.from_numpy(img).permute(2, 0, 1).float() / 255.0\n",
    "        \n",
    "        bbox = item['bbox']\n",
    "        bbox_scaled = [\n",
    "            bbox[0] * self.img_size / w,\n",
    "            bbox[1] * self.img_size / h,\n",
    "            bbox[2] * self.img_size / w,\n",
    "            bbox[3] * self.img_size / h\n",
    "        ]\n",
    "        \n",
    "        return img_tensor, {\n",
    "            'bbox': torch.tensor([bbox_scaled], dtype=torch.float32),\n",
    "            'cls': torch.tensor([item['label']], dtype=torch.long),\n",
    "            'img_scale': torch.tensor([1.0], dtype=torch.float32),\n",
    "            'img_size': torch.tensor([self.img_size, self.img_size], dtype=torch.long)\n",
    "        }\n",
    "\n",
    "def collate_fn(batch):\n",
    "    images = torch.stack([x[0] for x in batch])\n",
    "    max_boxes = max([x[1]['bbox'].shape[0] for x in batch])\n",
    "    \n",
    "    bboxes, classes, scales, sizes = [], [], [], []\n",
    "    for x in batch:\n",
    "        bbox, cls = x[1]['bbox'], x[1]['cls']\n",
    "        n = bbox.shape[0]\n",
    "        if n < max_boxes:\n",
    "            bbox = torch.cat([bbox, torch.zeros((max_boxes - n, 4))])\n",
    "            cls = torch.cat([cls, torch.ones(max_boxes - n, dtype=torch.long) * -1])\n",
    "        bboxes.append(bbox)\n",
    "        classes.append(cls)\n",
    "        scales.append(x[1]['img_scale'])\n",
    "        sizes.append(x[1]['img_size'])\n",
    "    \n",
    "    return images, {\n",
    "        'bbox': torch.stack(bboxes),\n",
    "        'cls': torch.stack(classes),\n",
    "        'img_scale': torch.stack(scales),\n",
    "        'img_size': torch.stack(sizes)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f8d61a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOLOv5 모델\n",
    "def train_yolo(data_yaml, epochs=100):\n",
    "    print(\"\\n YOLOv5 학습 시작\")\n",
    "    model = YOLO(str(YOLO_WEIGHTS_FILE))\n",
    "    \n",
    "    results = model.train(\n",
    "        data=str(data_yaml),\n",
    "        epochs=epochs,\n",
    "        imgsz=640,\n",
    "        batch=16,\n",
    "        name='yolov5_freshness',\n",
    "        device='0' if torch.cuda.is_available() else 'cpu',\n",
    "        patience=30,\n",
    "        workers=0,\n",
    "        project=str(RESULT_DIR)\n",
    "    )\n",
    "    \n",
    "    print(f\" YOLOv5 학습 완료\")\n",
    "    return model\n",
    "\n",
    "def test_yolo(model, data_yaml):\n",
    "    print(\"\\n YOLOv5 테스트셋 평가 시작\")\n",
    "    \n",
    "    test_metrics = model.val(\n",
    "        data=str(data_yaml),\n",
    "        split='test',\n",
    "        project=str(RESULT_DIR),\n",
    "        name='yolov5_test'\n",
    "    )\n",
    "    \n",
    "    yolo_test_metrics = {\n",
    "        'mAP50': float(test_metrics.box.map50),\n",
    "        'mAP50_95': float(test_metrics.box.map),\n",
    "        'precision': float(test_metrics.box.mp),\n",
    "        'recall': float(test_metrics.box.mr)\n",
    "    }\n",
    "    \n",
    "    print(f\"YOLOv5 테스트 완료\")\n",
    "    print(f\"  mAP@0.5: {yolo_test_metrics['mAP50']:.3f}\")\n",
    "    print(f\"  mAP@0.5:0.95: {yolo_test_metrics['mAP50_95']:.3f}\")\n",
    "    print(f\"  Precision: {yolo_test_metrics['precision']:.3f}\")\n",
    "    print(f\"  Recall: {yolo_test_metrics['recall']:.3f}\")\n",
    "    \n",
    "    # YOLO metrics 저장\n",
    "    yolo_metrics_path = RESULT_DIR / 'yolo_metrics.json'\n",
    "    with open(yolo_metrics_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump({\n",
    "            'summary': yolo_test_metrics\n",
    "        }, f, indent=4, ensure_ascii=False)\n",
    "    print(f\"YOLO metrics 저장: {yolo_metrics_path}\")\n",
    "    \n",
    "    return yolo_test_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c6bfa3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COCO 형태변환\n",
    "def create_coco_annotations(splits, classes):    \n",
    "    coco_categories = []\n",
    "    for idx, name in enumerate(classes): \n",
    "        coco_categories.append({\n",
    "            \"id\": idx, \n",
    "            \"name\": name, \n",
    "            \"supercategory\": \"freshness\"\n",
    "        })\n",
    "\n",
    "    for split in ['train', 'val', 'test']:\n",
    "        coco_images = []\n",
    "        coco_annotations = []\n",
    "        \n",
    "        coco_data = {\n",
    "            'info': {\n",
    "                \"description\": f\"Custom Dataset - {split} Set\",\n",
    "                \"version\": \"1.0\",\n",
    "                \"year\": 2025,\n",
    "                \"contributor\": \"Contributor\",\n",
    "                \"date_created\": \"2025/11/11\"\n",
    "            },\n",
    "            'licenses': [{\"id\": 0, \"name\": \"Unknown\", \"url\": \"\"}],\n",
    "            'categories': coco_categories,\n",
    "            'images': coco_images,\n",
    "            'annotations': coco_annotations\n",
    "        }\n",
    "        \n",
    "        ann_id = 0\n",
    "        \n",
    "        for img_id, item in enumerate(splits[split]):\n",
    "            try:\n",
    "                with open(str(item['image']), 'rb') as f:\n",
    "                    img = cv2.imdecode(np.frombuffer(f.read(), np.uint8), cv2.IMREAD_COLOR)\n",
    "                h, w = img.shape[:2]\n",
    "            except Exception as e:\n",
    "                print(f\"이미지 로드 실패 {item['image']}: {e}\")\n",
    "                continue\n",
    "            \n",
    "            coco_data['images'].append({\n",
    "                'id': img_id,\n",
    "                'file_name': str(item['image']),\n",
    "                'width': w,\n",
    "                'height': h\n",
    "            })\n",
    "            \n",
    "            bbox = item['bbox']\n",
    "            coco_data['annotations'].append({\n",
    "                'id': ann_id,\n",
    "                'image_id': img_id,\n",
    "                'category_id': item['label'],\n",
    "                'bbox': [bbox[0], bbox[1], bbox[2] - bbox[0], bbox[3] - bbox[1]],\n",
    "                'area': (bbox[2] - bbox[0]) * (bbox[3] - bbox[1]),\n",
    "                'iscrowd': 0\n",
    "            })\n",
    "            ann_id += 1\n",
    "        \n",
    "        anno_path = DATASET_EFFDET / f'coco_{split}.json'\n",
    "        with open(anno_path, 'w') as f:\n",
    "            json.dump(coco_data, f, indent=4)\n",
    "        \n",
    "        print(f\"COCO {split} annotations: {anno_path}\")\n",
    "    \n",
    "    return DATASET_EFFDET / 'coco_test.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "35405145",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EfficientDet 모델\n",
    "def train_efficientdet(splits, classes, epochs=100):\n",
    "    print(\"\\n EfficientDet 학습 시작\")\n",
    "    \n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    num_classes = len(classes)\n",
    "    \n",
    "    gt_anno_file = create_coco_annotations(splits, classes)\n",
    "\n",
    "    train_loader = DataLoader(EffDetDataset(splits['train']), batch_size=4,\n",
    "                             shuffle=True, collate_fn=collate_fn, num_workers=0)\n",
    "    val_loader = DataLoader(EffDetDataset(splits['val']), batch_size=4,\n",
    "                           collate_fn=collate_fn, num_workers=0)\n",
    "    \n",
    "    config = get_efficientdet_config('tf_efficientdet_d0')\n",
    "    config.num_classes = num_classes\n",
    "    config.image_size = (512, 512)\n",
    "    \n",
    "    model = DetBenchTrain(EfficientDet(config, pretrained_backbone=True), config)\n",
    "    model.to(device)\n",
    "    \n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=0.01, weight_decay=0.0001)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, epochs)\n",
    "    \n",
    "    best_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "    max_patience = 30\n",
    "    \n",
    "    train_losses, val_losses = [], []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for images, targets in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\"):\n",
    "            images = images.to(device)\n",
    "            targets = {k: v.to(device) for k, v in targets.items()}\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            output = model(images, targets)\n",
    "            loss = output['loss'] if isinstance(output, dict) else output\n",
    "            \n",
    "            if torch.isnan(loss):\n",
    "                print(\"NaN loss detected\")\n",
    "                continue\n",
    "            \n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 10.0)\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "        \n",
    "        train_loss /= len(train_loader)\n",
    "        train_losses.append(train_loss)\n",
    "        \n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for images, targets in val_loader:\n",
    "                images = images.to(device)\n",
    "                targets = {k: v.to(device) for k, v in targets.items()}\n",
    "                output = model(images, targets)\n",
    "                loss = output['loss'] if isinstance(output, dict) else output\n",
    "                val_loss += loss.item()\n",
    "        \n",
    "        val_loss /= len(val_loader)\n",
    "        val_losses.append(val_loss) \n",
    "        print(f\"Epoch {epoch+1}: Train={train_loss:.4f}, Val={val_loss:.4f}\")\n",
    "\n",
    "        if epoch == 0 or val_loss < best_loss:\n",
    "            if val_loss < best_loss:\n",
    "                best_loss = val_loss\n",
    "            \n",
    "            patience_counter = 0\n",
    "            torch.save({\n",
    "                'model_state_dict': model.model.state_dict(),\n",
    "                'config': config\n",
    "            }, RESULT_DIR / 'efficientdet_best.pth')\n",
    "            print(f\"Saved (Loss: {best_loss:.4f})\")\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= max_patience:\n",
    "                print(f\"Early stopping at epoch {epoch+1}\")\n",
    "                break\n",
    "        \n",
    "        scheduler.step()\n",
    "    \n",
    "    print(f\"EfficientDet 학습 완료 (Best Loss: {best_loss:.4f})\")\n",
    "\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.plot(train_losses, label='Train Loss')\n",
    "    plt.plot(val_losses, label='Validation Loss')\n",
    "    plt.title(\"EfficientDet Training Loss Curve\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(RESULT_DIR / \"efficientdet_loss_curve.png\")\n",
    "    plt.close()\n",
    "    print(f\" EfficientDet 학습 곡선 저장됨: {RESULT_DIR / 'efficientdet_loss_curve.png'}\")\n",
    "\n",
    "    return model, config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3181a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_efficientdet_with_confusion_matrix(config, splits, classes, device):\n",
    "    print(\"\\n EfficientDet Confusion Matrix 평가 시작\")\n",
    "    \n",
    "    from effdet import EfficientDet, DetBenchPredict\n",
    "    \n",
    "    checkpoint_path = RESULT_DIR / 'efficientdet_best.pth'\n",
    "    if not checkpoint_path.exists():\n",
    "        print(\"모델 가중치 파일이 없습니다\")\n",
    "        return None\n",
    "    \n",
    "    checkpoint = torch.load(checkpoint_path, weights_only=False)\n",
    "    net = EfficientDet(config, pretrained_backbone=False)\n",
    "    net.load_state_dict(checkpoint['model_state_dict'])\n",
    "    predictor = DetBenchPredict(net).to(device).eval()\n",
    "    \n",
    "    test_data = splits['test']\n",
    "    \n",
    "    y_true = []  \n",
    "    y_pred = []  \n",
    "    \n",
    "    def calculate_iou(box1, box2):\n",
    "        x1 = max(box1[0], box2[0])\n",
    "        y1 = max(box1[1], box2[1])\n",
    "        x2 = min(box1[2], box2[2])\n",
    "        y2 = min(box1[3], box2[3])\n",
    "        \n",
    "        inter = max(0, x2 - x1) * max(0, y2 - y1)\n",
    "        area1 = (box1[2] - box1[0]) * (box1[3] - box1[1])\n",
    "        area2 = (box2[2] - box2[0]) * (box2[3] - box2[1])\n",
    "        union = area1 + area2 - inter\n",
    "        \n",
    "        return inter / union if union > 0 else 0\n",
    "    \n",
    "    print(\"\\n 테스트 데이터 예측 중\")\n",
    "    for item in tqdm(test_data, desc=\"Predicting\"):\n",
    "        with open(item['image'], 'rb') as f:\n",
    "            img = cv2.imdecode(np.frombuffer(f.read(), np.uint8), cv2.IMREAD_COLOR)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        h, w = img.shape[:2]\n",
    "        \n",
    "        img_resized = cv2.resize(img, (512, 512))\n",
    "        img_tensor = torch.from_numpy(img_resized).permute(2, 0, 1).float() / 255.0\n",
    "        img_tensor = img_tensor.unsqueeze(0).to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            pred = predictor(img_tensor)\n",
    "        \n",
    "        gt_box = item['bbox']\n",
    "        gt_label = item['label']\n",
    "        y_true.append(gt_label)\n",
    "        \n",
    "        # 예측 결과 처리\n",
    "        best_pred_label = -1 \n",
    "        best_iou = 0\n",
    "        confidence_threshold = 0.3 \n",
    "        \n",
    "        if len(pred) > 0 and pred[0].shape[0] > 0:\n",
    "            pred_np = pred[0].cpu().numpy()\n",
    "            \n",
    "            for box in pred_np:\n",
    "                if box[4] < confidence_threshold:\n",
    "                    continue\n",
    "                \n",
    "                pred_box = [\n",
    "                    box[0] * w / 512, \n",
    "                    box[1] * h / 512,\n",
    "                    box[2] * w / 512, \n",
    "                    box[3] * h / 512\n",
    "                ]\n",
    "                pred_label = int(box[5]) if len(box) > 5 else 0\n",
    "                \n",
    "                iou = calculate_iou(gt_box, pred_box)\n",
    "                \n",
    "                if iou > best_iou and iou >= 0.5:\n",
    "                    best_iou = iou\n",
    "                    best_pred_label = pred_label\n",
    "        \n",
    "        if best_pred_label == -1:\n",
    "            if len(pred) > 0 and pred[0].shape[0] > 0:\n",
    "                pred_np = pred[0].cpu().numpy()\n",
    "                valid_preds = pred_np[pred_np[:, 4] >= confidence_threshold]\n",
    "                if len(valid_preds) > 0:\n",
    "                    best_idx = np.argmax(valid_preds[:, 4])\n",
    "                    best_pred_label = int(valid_preds[best_idx, 5])\n",
    "                else:\n",
    "                    if len(pred_np) > 0:\n",
    "                        best_idx = np.argmax(pred_np[:, 4])\n",
    "                        best_pred_label = int(pred_np[best_idx, 5])\n",
    "        \n",
    "        if best_pred_label == -1:\n",
    "            best_pred_label = len(classes)\n",
    "        \n",
    "        y_pred.append(best_pred_label)\n",
    "    \n",
    "    print(\"\\n Confusion Matrix 생성 중\")\n",
    "    \n",
    "    extended_classes = classes + ['No Detection']\n",
    "    \n",
    "    cm = confusion_matrix(y_true, y_pred, labels=list(range(len(extended_classes))))\n",
    "    \n",
    "    plt.figure(figsize=(max(12, len(extended_classes) * 0.8), max(10, len(extended_classes) * 0.7)))\n",
    "    \n",
    "    # 정규화된 Confusion Matrix\n",
    "    cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    cm_normalized = np.nan_to_num(cm_normalized)\n",
    "    \n",
    "    sns.heatmap(cm_normalized, annot=True, fmt='.2f', cmap='Blues', \n",
    "                xticklabels=extended_classes, yticklabels=extended_classes,\n",
    "                cbar_kws={'label': 'Normalized Count'})\n",
    "    \n",
    "    plt.title('EfficientDet Confusion Matrix (Normalized)', fontsize=14, fontweight='bold')\n",
    "    plt.ylabel('True Label', fontsize=12, fontweight='bold')\n",
    "    plt.xlabel('Predicted Label', fontsize=12, fontweight='bold')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.yticks(rotation=0)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # 저장\n",
    "    cm_path = RESULT_DIR / 'efficientdet_confusion_matrix_normalized.png'\n",
    "    plt.savefig(cm_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\" 정규화된 Confusion Matrix 저장: {cm_path}\")\n",
    "    \n",
    "\n",
    "    plt.figure(figsize=(max(12, len(extended_classes) * 0.8), max(10, len(extended_classes) * 0.7)))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=extended_classes, yticklabels=extended_classes,\n",
    "                cbar_kws={'label': 'Count'})\n",
    "    \n",
    "    plt.title('EfficientDet Confusion Matrix (Count)', fontsize=14, fontweight='bold')\n",
    "    plt.ylabel('True Label', fontsize=12, fontweight='bold')\n",
    "    plt.xlabel('Predicted Label', fontsize=12, fontweight='bold')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.yticks(rotation=0)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    cm_count_path = RESULT_DIR / 'efficientdet_confusion_matrix_count.png'\n",
    "    plt.savefig(cm_count_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\" 개수 Confusion Matrix 저장: {cm_count_path}\")\n",
    "    \n",
    "    print(\"\\n Classification Report:\")\n",
    "    print(\"=\"*70)\n",
    "    # No Detection 제외한 실제 클래스만으로 리포트 생성\n",
    "    valid_indices = [i for i, label in enumerate(y_pred) if label < len(classes)]\n",
    "    if valid_indices:\n",
    "        y_true_valid = [y_true[i] for i in valid_indices]\n",
    "        y_pred_valid = [y_pred[i] for i in valid_indices]\n",
    "        \n",
    "        # 실제로 예측된 클래스만 추출\n",
    "        unique_labels = sorted(list(set(y_true_valid + y_pred_valid)))\n",
    "        target_names_subset = [classes[i] for i in unique_labels if i < len(classes)]\n",
    "        \n",
    "        report = classification_report(y_true_valid, y_pred_valid, \n",
    "                                       labels=unique_labels,\n",
    "                                       target_names=target_names_subset, \n",
    "                                       zero_division=0)\n",
    "        print(report)\n",
    "        \n",
    "        # Classification Report 저장\n",
    "        report_path = RESULT_DIR / 'efficientdet_classification_report.txt'\n",
    "        with open(report_path, 'w', encoding='utf-8') as f:\n",
    "            f.write(report)\n",
    "        print(f\"\\n Classification Report 저장: {report_path}\")\n",
    "    \n",
    "    # 클래스별 정확도 계산\n",
    "    class_accuracies = {}\n",
    "    for i, class_name in enumerate(classes):\n",
    "        if cm[i].sum() > 0:\n",
    "            accuracy = cm[i, i] / cm[i].sum()\n",
    "            class_accuracies[class_name] = accuracy\n",
    "    \n",
    "    # 클래스별 정확도 시각화\n",
    "    if class_accuracies:\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        sorted_classes = sorted(class_accuracies.items(), key=lambda x: x[1], reverse=True)\n",
    "        class_names = [x[0] for x in sorted_classes]\n",
    "        accuracies = [x[1] for x in sorted_classes]\n",
    "        \n",
    "        bars = plt.bar(range(len(class_names)), accuracies, color='skyblue', edgecolor='navy')\n",
    "        plt.xlabel('Class', fontsize=12, fontweight='bold')\n",
    "        plt.ylabel('Accuracy', fontsize=12, fontweight='bold')\n",
    "        plt.title('EfficientDet: Per-Class Accuracy', fontsize=14, fontweight='bold')\n",
    "        plt.xticks(range(len(class_names)), class_names, rotation=45, ha='right')\n",
    "        plt.ylim(0, 1.1)\n",
    "        plt.grid(axis='y', alpha=0.3)\n",
    "        \n",
    "        # 값 표시\n",
    "        for bar in bars:\n",
    "            height = bar.get_height()\n",
    "            plt.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                    f'{height:.2f}',\n",
    "                    ha='center', va='bottom', fontsize=9)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        acc_path = RESULT_DIR / 'efficientdet_per_class_accuracy.png'\n",
    "        plt.savefig(acc_path, dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        print(f\" 클래스별 정확도 그래프 저장: {acc_path}\")\n",
    "    \n",
    "    # 전체 정확도 계산\n",
    "    total_correct = np.trace(cm[:len(classes), :len(classes)])  # No Detection 제외\n",
    "    total_samples = cm[:len(classes), :].sum()\n",
    "    overall_accuracy = total_correct / total_samples if total_samples > 0 else 0\n",
    "    \n",
    "    print(f\"\\n 전체 정확도: {overall_accuracy:.3f}\")\n",
    "    print(f\" 총 테스트 샘플: {len(y_true)}개\")\n",
    "    print(f\" 정확히 분류된 샘플: {total_correct}개\")\n",
    "    \n",
    "    # Confusion Matrix 데이터 저장\n",
    "    cm_data = {\n",
    "        'confusion_matrix': cm.tolist(),\n",
    "        'classes': extended_classes,\n",
    "        'overall_accuracy': float(overall_accuracy),\n",
    "        'class_accuracies': {k: float(v) for k, v in class_accuracies.items()},\n",
    "        'total_samples': int(total_samples),\n",
    "        'correct_predictions': int(total_correct)\n",
    "    }\n",
    "    \n",
    "    cm_json_path = RESULT_DIR / 'efficientdet_confusion_matrix.json'\n",
    "    import json\n",
    "    with open(cm_json_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(cm_data, f, indent=2, ensure_ascii=False)\n",
    "    print(f\" Confusion Matrix 데이터 저장: {cm_json_path}\")\n",
    "    \n",
    "    return cm, class_accuracies, overall_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e5e7377a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_efficientdet(config, splits, classes):\n",
    "    print(\"\\n EfficientDet 테스트셋 평가 시작\")\n",
    "    \n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "\n",
    "    if COCO_AVAILABLE and len(splits['test']) > 0:\n",
    "        gt_anno_file = DATASET_EFFDET / 'coco_test.json'\n",
    "        effdet_test_metrics = evaluate_efficientdet_coco(config, splits, classes, device, gt_anno_file)\n",
    "    else:\n",
    "        effdet_test_metrics = evaluate_efficientdet_simple(config, splits, classes, device)\n",
    "\n",
    "    cm, class_accuracies, overall_accuracy = evaluate_efficientdet_with_confusion_matrix(\n",
    "        config, splits, classes, device\n",
    "    )\n",
    "    \n",
    "    effdet_test_metrics['overall_accuracy'] = overall_accuracy\n",
    "    effdet_test_metrics['class_accuracies'] = class_accuracies\n",
    "    \n",
    "    effdet_test_metrics.setdefault('mAP50', 0.0)\n",
    "    effdet_test_metrics.setdefault('mAP50_95', 0.0)\n",
    "    effdet_test_metrics.setdefault('precision', 0.0)\n",
    "    effdet_test_metrics.setdefault('recall', 0.0)\n",
    "    \n",
    "    print(f\"\\nEfficientDet 테스트 완료\")\n",
    "    print(f\" mAP@0.5: {effdet_test_metrics['mAP50']:.3f}\")\n",
    "    print(f\" mAP@0.5:0.95: {effdet_test_metrics['mAP50_95']:.3f}\")\n",
    "    print(f\" Precision: {effdet_test_metrics['precision']:.3f}\")\n",
    "    print(f\" Recall: {effdet_test_metrics['recall']:.3f}\")\n",
    "    print(f\" Overall Accuracy: {overall_accuracy:.3f}\")\n",
    "    \n",
    "    return effdet_test_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "79c8ee98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_efficientdet_coco(config, splits, classes, device, gt_anno_file):\n",
    "    print(\"\\nEfficientDet COCO 평가 시작\")\n",
    "\n",
    "    checkpoint_path = RESULT_DIR / 'efficientdet_best.pth'\n",
    "    if not checkpoint_path.exists():\n",
    "        print(\"모델 가중치 파일이 없습니다:\", checkpoint_path)\n",
    "        return {'mAP50': 0.0, 'mAP50_95': 0.0, 'precision': 0.0, 'recall': 0.0}\n",
    "\n",
    "    checkpoint = torch.load(checkpoint_path, weights_only=False)\n",
    "    net = EfficientDet(config, pretrained_backbone=False)\n",
    "    net.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "    bench = DetBenchPredict(net)\n",
    "    bench.eval()\n",
    "    bench.to(device)\n",
    "\n",
    "    coco_gt = COCO(str(gt_anno_file))\n",
    "\n",
    "    results = []\n",
    "    test_data = splits['test']\n",
    "\n",
    "    vis_dir = RESULT_DIR / 'efficientdet_test_predictions'\n",
    "    vis_dir.mkdir(exist_ok=True)\n",
    "\n",
    "    for img_id, item in enumerate(tqdm(test_data, desc=\"Predicting on Test Set\")):\n",
    "        img = cv2.imread(item['image'])\n",
    "        if img is None:\n",
    "            continue\n",
    "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        h, w = img_rgb.shape[:2]\n",
    "\n",
    "        img_resized = cv2.resize(img_rgb, (512, 512))\n",
    "        img_tensor = torch.from_numpy(img_resized).permute(2, 0, 1).float() / 255.0\n",
    "        img_tensor = img_tensor.unsqueeze(0).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            detections = bench(img_tensor)\n",
    "\n",
    "        if detections is None or len(detections.shape) != 3:\n",
    "            continue\n",
    "\n",
    "        det = detections[0].cpu().numpy()\n",
    "        for i in range(det.shape[0]):\n",
    "            if det.shape[1] < 6:\n",
    "                continue\n",
    "            score = float(det[i, 4])\n",
    "            class_id = int(det[i, 5])\n",
    "            if score < 0.001:\n",
    "                continue\n",
    "\n",
    "            x1, y1, x2, y2 = det[i, :4]\n",
    "            x1 = float(x1 * w / 512)\n",
    "            y1 = float(y1 * h / 512)\n",
    "            x2 = float(x2 * w / 512)\n",
    "            y2 = float(y2 * h / 512)\n",
    "            \n",
    "            if x2 <= x1 or y2 <= y1 or class_id < 0 or class_id >= len(classes):\n",
    "                continue\n",
    "\n",
    "            results.append({\n",
    "                'image_id': int(img_id),\n",
    "                'category_id': int(class_id),\n",
    "                'bbox': [x1, y1, x2 - x1, y2 - y1],\n",
    "                'score': float(score)\n",
    "            })\n",
    "\n",
    "    if not results:\n",
    "        print(\"예측 결과 없음\")\n",
    "        return {'mAP50': 0.0, 'mAP50_95': 0.0, 'precision': 0.0, 'recall': 0.0}\n",
    "\n",
    "    pred_file = RESULT_DIR / 'coco_test_predictions.json'\n",
    "    with open(pred_file, 'w') as f:\n",
    "        json.dump(results, f)\n",
    "\n",
    "    try:\n",
    "        coco_dt = coco_gt.loadRes(str(pred_file))\n",
    "        coco_eval = COCOeval(coco_gt, coco_dt, 'bbox')\n",
    "        coco_eval.evaluate()\n",
    "        coco_eval.accumulate()\n",
    "        coco_eval.summarize()\n",
    "\n",
    "        metrics = {\n",
    "            'mAP50_95': float(coco_eval.stats[0]),\n",
    "            'mAP50': float(coco_eval.stats[1]),\n",
    "            'precision': float(coco_eval.stats[0]),\n",
    "            'recall': float(coco_eval.stats[8])\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"COCO 평가 중 오류: {e}\")\n",
    "        return {'mAP50': 0.0, 'mAP50_95': 0.0, 'precision': 0.0, 'recall': 0.0}\n",
    "    \n",
    "        # EfficientDet metrics 저장\n",
    "    effdet_metrics_path = RESULT_DIR / 'efficientdet_metrics.json'\n",
    "    with open(effdet_metrics_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump({\n",
    "            'summary': metrics\n",
    "        }, f, indent=4, ensure_ascii=False)\n",
    "    print(f\"EfficientDet metrics 저장: {effdet_metrics_path}\")\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "551c4448",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_efficientdet_simple(config, splits, classes, device):\n",
    "    print(\"\\n EfficientDet Simple 평가 중\")\n",
    "    \n",
    "    checkpoint_path = RESULT_DIR / 'efficientdet_best.pth'\n",
    "    if not checkpoint_path.exists():\n",
    "        print(\"모델 가중치 파일이 없습니다\")\n",
    "        return {'mAP50': 0.0, 'mAP50_95': 0.0, 'precision': 0.0, 'recall': 0.0}\n",
    "    \n",
    "    checkpoint = torch.load(checkpoint_path, weights_only=False)\n",
    "    net = EfficientDet(config, pretrained_backbone=False)\n",
    "    net.load_state_dict(checkpoint['model_state_dict'])\n",
    "    predictor = DetBenchPredict(net).to(device).eval()\n",
    "    \n",
    "    test_data = splits['test']\n",
    "    \n",
    "    def calculate_iou(box1, box2):\n",
    "        x1 = max(box1[0], box2[0])\n",
    "        y1 = max(box1[1], box2[1])\n",
    "        x2 = min(box1[2], box2[2])\n",
    "        y2 = min(box1[3], box2[3])\n",
    "        \n",
    "        inter = max(0, x2 - x1) * max(0, y2 - y1)\n",
    "        area1 = (box1[2] - box1[0]) * (box1[3] - box1[1])\n",
    "        area2 = (box2[2] - box2[0]) * (box2[3] - box2[1])\n",
    "        union = area1 + area2 - inter\n",
    "        \n",
    "        return inter / union if union > 0 else 0\n",
    "    \n",
    "    correct_50 = 0\n",
    "    all_ious = []\n",
    "    \n",
    "    for item in tqdm(test_data, desc=\"Evaluating\"):\n",
    "        with open(item['image'], 'rb') as f:\n",
    "            img = cv2.imdecode(np.frombuffer(f.read(), np.uint8), cv2.IMREAD_COLOR)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        h, w = img.shape[:2]\n",
    "        \n",
    "        img_resized = cv2.resize(img, (512, 512))\n",
    "        img_tensor = torch.from_numpy(img_resized).permute(2, 0, 1).float() / 255.0\n",
    "        img_tensor = img_tensor.unsqueeze(0).to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            pred = predictor(img_tensor)\n",
    "        \n",
    "        gt_box = item['bbox']\n",
    "        gt_label = item['label']\n",
    "        \n",
    "        best_iou = 0\n",
    "        \n",
    "        if len(pred) > 0 and pred[0].shape[0] > 0:\n",
    "            pred_np = pred[0].cpu().numpy()\n",
    "            for box in pred_np:\n",
    "                if box[4] < 0.1:\n",
    "                    continue\n",
    "                \n",
    "                pred_box = [\n",
    "                    box[0] * w / 512, box[1] * h / 512,\n",
    "                    box[2] * w / 512, box[3] * h / 512\n",
    "                ]\n",
    "                pred_label = int(box[5]) if len(box) > 5 else 0\n",
    "                \n",
    "                if pred_label == gt_label:\n",
    "                    iou = calculate_iou(gt_box, pred_box)\n",
    "                    best_iou = max(best_iou, iou)\n",
    "        \n",
    "        all_ious.append(best_iou)\n",
    "        if best_iou >= 0.5:\n",
    "            correct_50 += 1\n",
    "    \n",
    "    total = len(test_data)\n",
    "    mAP_50 = correct_50 / total if total > 0 else 0\n",
    "    \n",
    "    mAP_50_95_sum = 0\n",
    "    for thresh in [0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95]:\n",
    "        correct = sum([1 for iou in all_ious if iou >= thresh])\n",
    "        mAP_50_95_sum += (correct / total if total > 0 else 0)\n",
    "    mAP_50_95 = mAP_50_95_sum / 10\n",
    "    \n",
    "    metrics = {\n",
    "        'mAP50': float(mAP_50),\n",
    "        'mAP50_95': float(mAP_50_95),\n",
    "        'precision': float(mAP_50),\n",
    "        'recall': float(mAP_50)\n",
    "    }\n",
    "\n",
    "        # EfficientDet metrics 저장\n",
    "    effdet_metrics_path = RESULT_DIR / 'efficientdet_metrics.json'\n",
    "    with open(effdet_metrics_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump({\n",
    "            'summary': metrics\n",
    "        }, f, indent=4, ensure_ascii=False)\n",
    "    print(f\"EfficientDet metrics 저장: {effdet_metrics_path}\")\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f95c4677",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_comparison(yolo_metrics, effdet_metrics, title_suffix=\"\"):\n",
    "    metrics_names = ['mAP@0.5', 'mAP@0.5:0.95', 'Precision', 'Recall']\n",
    "    yolo_values = [\n",
    "        yolo_metrics['mAP50'],\n",
    "        yolo_metrics['mAP50_95'],\n",
    "        yolo_metrics['precision'],\n",
    "        yolo_metrics['recall']\n",
    "    ]\n",
    "    effdet_values = [\n",
    "        effdet_metrics['mAP50'],\n",
    "        effdet_metrics['mAP50_95'],\n",
    "        effdet_metrics['precision'],\n",
    "        effdet_metrics['recall']\n",
    "    ]\n",
    "    \n",
    "    x = np.arange(len(metrics_names))\n",
    "    width = 0.35\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    bars1 = ax.bar(x - width/2, yolo_values, width, label='YOLOv5', color='#FF6B6B')\n",
    "    bars2 = ax.bar(x + width/2, effdet_values, width, label='EfficientDet', color='#4ECDC4')\n",
    "    \n",
    "    ax.set_xlabel('Metrics', fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel('Score', fontsize=12, fontweight='bold')\n",
    "    ax.set_title(f'YOLOv5 vs EfficientDet Performance Comparison{title_suffix}', fontsize=14, fontweight='bold')\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(metrics_names)\n",
    "    ax.legend(fontsize=11)\n",
    "    ax.set_ylim(0, 1.1)\n",
    "    ax.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    for bars in [bars1, bars2]:\n",
    "        for bar in bars:\n",
    "            height = bar.get_height()\n",
    "            ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                   f'{height:.3f}',\n",
    "                   ha='center', va='bottom', fontsize=9)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    filename = 'performance_comparison_test.png' if title_suffix else 'performance_comparison.png'\n",
    "    plt.savefig(RESULT_DIR / filename, dpi=300, bbox_inches='tight')\n",
    "    print(f\"\\n 비교 그래프 저장: {RESULT_DIR / filename}\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d04b7e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results_table(yolo_metrics, effdet_metrics, title=\"성능 비교\"):\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(f\"{title:^70}\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"\\n{'Metric':<20} {'YOLOv5':<15} {'EfficientDet':<15} {'Difference':<15}\")\n",
    "    print(\"-\"*70)\n",
    "    print(f\"{'mAP@0.5':<20} {yolo_metrics['mAP50']:<15.3f} {effdet_metrics['mAP50']:<15.3f} {yolo_metrics['mAP50']-effdet_metrics['mAP50']:+.3f}\")\n",
    "    print(f\"{'mAP@0.5:0.95':<20} {yolo_metrics['mAP50_95']:<15.3f} {effdet_metrics['mAP50_95']:<15.3f} {yolo_metrics['mAP50_95']-effdet_metrics['mAP50_95']:+.3f}\")\n",
    "    print(f\"{'Precision':<20} {yolo_metrics['precision']:<15.3f} {effdet_metrics['precision']:<15.3f} {yolo_metrics['precision']-effdet_metrics['precision']:+.3f}\")\n",
    "    print(f\"{'Recall':<20} {yolo_metrics['recall']:<15.3f} {effdet_metrics['recall']:<15.3f} {yolo_metrics['recall']-effdet_metrics['recall']:+.3f}\")\n",
    "    \n",
    "    if yolo_metrics['mAP50'] > effdet_metrics['mAP50']:\n",
    "        winner = \"YOLOv5\"\n",
    "        diff = yolo_metrics['mAP50'] - effdet_metrics['mAP50']\n",
    "    elif effdet_metrics['mAP50'] > yolo_metrics['mAP50']:\n",
    "        winner = \"EfficientDet\"\n",
    "        diff = effdet_metrics['mAP50'] - yolo_metrics['mAP50']\n",
    "    else:\n",
    "        winner = \"동점\"\n",
    "        diff = 0\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    if winner != \"동점\":\n",
    "        print(f\"{winner}가 {diff:.3f}만큼 더 높은 mAP@0.5를 달성했습니다!\")\n",
    "    else:\n",
    "        print(f\"두 모델이 동일한 성능을 보였습니다!\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    return winner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "33765e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_models_final():\n",
    "    yolo_metrics_path = RESULT_DIR / \"yolo_metrics.json\"\n",
    "    effdet_metrics_path = RESULT_DIR / \"efficientdet_metrics.json\"\n",
    "    \n",
    "    if not yolo_metrics_path.exists() or not effdet_metrics_path.exists():\n",
    "        print(\"metrics 파일이 없습니다. 평가가 완료되지 않았습니다.\")\n",
    "        return\n",
    "\n",
    "    with open(yolo_metrics_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        yolo_data = json.load(f)\n",
    "    with open(effdet_metrics_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        effdet_data = json.load(f)\n",
    "\n",
    "    yolo_summary = yolo_data.get(\"summary\", {})\n",
    "    effdet_summary = effdet_data.get(\"summary\", {})\n",
    "\n",
    "    metrics_names = [\"mAP@0.5\", \"mAP@0.5:0.95\", \"Precision\", \"Recall\"]\n",
    "    metric_keys = [\"mAP50\", \"mAP50_95\", \"precision\", \"recall\"]\n",
    "\n",
    "    yolo_scores = [yolo_summary.get(k, 0) for k in metric_keys]\n",
    "    effdet_scores = [effdet_summary.get(k, 0) for k in metric_keys]\n",
    "\n",
    "    x = np.arange(len(metrics_names))\n",
    "    width = 0.35\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(x - width/2, yolo_scores, width, label=\"YOLOv5\", color='red', alpha=0.8)\n",
    "    plt.bar(x + width/2, effdet_scores, width, label=\"EfficientDet\", color='blue', alpha=0.8)\n",
    "\n",
    "    plt.xticks(x, metrics_names, fontsize=11)\n",
    "    plt.ylabel(\"Score\", fontsize=12, fontweight='bold')\n",
    "    plt.ylim(0, 1)\n",
    "    plt.title(\"YOLOv5 vs EfficientDet 최종 성능 비교\", fontsize=14, fontweight='bold')\n",
    "    plt.legend(fontsize=11)\n",
    "    plt.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # 값 표시\n",
    "    for i, (y_score, e_score) in enumerate(zip(yolo_scores, effdet_scores)):\n",
    "        if y_score > 0:\n",
    "            plt.text(i - width/2, y_score, f'{y_score:.3f}', ha='center', va='bottom', fontsize=9)\n",
    "        if e_score > 0:\n",
    "            plt.text(i + width/2, e_score, f'{e_score:.3f}', ha='center', va='bottom', fontsize=9)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "\n",
    "    save_path = RESULT_DIR / \"final_comparison_graph.png\"\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "    print(f\"\\n 최종 성능 비교 그래프 저장 완료 → {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e5d7b249",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    print(\"YOLOv5 vs EfficientDet 성능 비교 (실제 테스트 데이터)\")\n",
    "    \n",
    "    # 1. 데이터 전처리\n",
    "    print(\"\\n 1단계 데이터 전처리\")\n",
    "    print(f\"   원천데이터 경로: {JSON_DIR}\")\n",
    "    \n",
    "    splits, classes = preprocess_data()\n",
    "    if not classes:\n",
    "        print(\"데이터셋 없음\")\n",
    "        return\n",
    "    \n",
    "    if len(splits['test']) == 0:\n",
    "        print(\"\\n 오류: 테스트 데이터가 없습니다!\")\n",
    "        print(f\"   다음 경로를 확인해주세요:\")\n",
    "        return\n",
    "    \n",
    "    print(f\"\\n클래스 목록 ({len(classes)}개):\")\n",
    "    for i, cls in enumerate(classes):\n",
    "        print(f\"  {i}: {cls}\")\n",
    "    \n",
    "    # 2. YOLOv5 학습\n",
    "    print(\"2단계 YOLOv5 학습\")\n",
    "    prepare_yolo_dataset(splits, classes)\n",
    "    yolo_model = train_yolo(DATASET_YOLO / 'data.yaml', epochs=5)\n",
    "\n",
    "    # 3. EfficientDet 학습\n",
    "    print(\"3단계 EfficientDet 학습\")\n",
    "    effdet_model, effdet_config = train_efficientdet(splits, classes, epochs=30)\n",
    "    \n",
    "    # 4. 테스트셋 평가\n",
    "    print(\"4단계 실제 테스트 데이터로 최종 평가\")\n",
    "    print(f\"   테스트 이미지 수: {len(splits['test'])}개\")\n",
    "    \n",
    "    # YOLOv5 테스트\n",
    "    yolo_test_metrics = test_yolo(yolo_model, DATASET_YOLO / 'data.yaml')\n",
    "    \n",
    "    # EfficientDet 테스트\n",
    "    effdet_test_metrics = test_efficientdet(effdet_config, splits, classes)\n",
    "    \n",
    "    # 5. 결과 비교 및 시각화\n",
    "    print(\"【5단계】 결과 비교 및 시각화\")\n",
    "    \n",
    "    winner = print_results_table(yolo_test_metrics, effdet_test_metrics, \"실제 테스트 데이터 최종 성능 비교\")\n",
    "    visualize_comparison(yolo_test_metrics, effdet_test_metrics, \" (Real Test Data)\")\n",
    "    \n",
    "    # 최종 비교 그래프\n",
    "    compare_models_final()\n",
    "    \n",
    "    # 6. 결과 저장\n",
    "    results_summary = {\n",
    "        'dataset_info': {\n",
    "            'train_source': 'data/raw (80%)',\n",
    "            'val_source': 'data/raw (20%)',\n",
    "            'test_source': 'data/test_data (별도)',\n",
    "            'num_train': len(splits['train']),\n",
    "            'num_val': len(splits['val']),\n",
    "            'num_test': len(splits['test']),\n",
    "            'classes': classes\n",
    "        },\n",
    "        'yolo_test': yolo_test_metrics,\n",
    "        'efficientdet_test': effdet_test_metrics,\n",
    "        'winner': winner\n",
    "    }\n",
    "    \n",
    "    with open(RESULT_DIR / 'final_test_results.json', 'w', encoding='utf-8') as f:\n",
    "        json.dump(results_summary, f, indent=2, ensure_ascii=False)\n",
    "    \n",
    "    # 7. 간단한 요약 그래프\n",
    "    labels = ['mAP@0.5', 'mAP@0.5:0.95']\n",
    "    yolo_scores = [yolo_test_metrics['mAP50'], yolo_test_metrics['mAP50_95']]\n",
    "    effdet_scores = [effdet_test_metrics['mAP50'], effdet_test_metrics['mAP50_95']]\n",
    "\n",
    "    x = np.arange(len(labels))\n",
    "    width = 0.35\n",
    "\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.bar(x - width/2, yolo_scores, width, label='YOLOv5', color='red', alpha=0.8)\n",
    "    plt.bar(x + width/2, effdet_scores, width, label='EfficientDet', color='blue', alpha=0.8)\n",
    "\n",
    "    plt.ylabel('Score', fontsize=12, fontweight='bold')\n",
    "    plt.title('Real Test Data: YOLOv5 vs EfficientDet', fontsize=14, fontweight='bold')\n",
    "    plt.xticks(x, labels, fontsize=11)\n",
    "    plt.legend(fontsize=11)\n",
    "    plt.ylim(0, 1.1)\n",
    "    plt.grid(True, axis='y', linestyle='--', alpha=0.3)\n",
    "    \n",
    "    for i, (y_score, e_score) in enumerate(zip(yolo_scores, effdet_scores)):\n",
    "        plt.text(i - width/2, y_score, f'{y_score:.3f}', ha='center', va='bottom', fontsize=9)\n",
    "        plt.text(i + width/2, e_score, f'{e_score:.3f}', ha='center', va='bottom', fontsize=9)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(RESULT_DIR / 'test_summary_graph.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # 최종 출력\n",
    "    print(\"모든 작업 완료!\")\n",
    "    print(f\"\\n 결과 저장 위치: {RESULT_DIR.resolve()}\")\n",
    "    print(f\"\\n 생성된 파일:\")\n",
    "    print(f\"  YOLOv5 테스트: yolov5_test/\")\n",
    "    print(f\"  EfficientDet 테스트 예측: efficientdet_test_predictions/\")\n",
    "    print(f\"  성능 비교 그래프: performance_comparison_test.png\")\n",
    "    print(f\"  최종 비교 그래프: final_comparison_graph.png\")\n",
    "    print(f\"  요약 그래프: test_summary_graph.png\")\n",
    "    print(f\"  결과 JSON: final_test_results.json\")\n",
    "    print(f\"  YOLO metrics: yolo_metrics.json\")\n",
    "    print(f\"  EfficientDet metrics: efficientdet_metrics.json\")\n",
    "    \n",
    "    print(f\"\\n 데이터 구성:\")\n",
    "    print(f\"  - 학습: {len(splits['train'])}개 (원천데이터 80%)\")\n",
    "    print(f\"  - 검증: {len(splits['val'])}개 (원천데이터 20%)\")\n",
    "    print(f\"  - 테스트: {len(splits['test'])}개 (별도 실제 데이터)\")\n",
    "    \n",
    "    print(f\"\\n 최종 승자: {winner}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a5937462",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLOv5 vs EfficientDet 성능 비교 (실제 테스트 데이터)\n",
      "\n",
      " 1단계 데이터 전처리\n",
      "   원천데이터 경로: c:\\miniproject\\data정리\\data\\raw\\json_labels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading train: 100%|██████████| 72/72 [00:00<00:00, 2344.53it/s]\n",
      "Loading val: 100%|██████████| 9/9 [00:00<00:00, 1795.76it/s]\n",
      "Loading test: 100%|██████████| 9/9 [00:00<00:00, 2246.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: train=72, val=9, test=9\n",
      "\n",
      "클래스 목록 (9개):\n",
      "  0: 배_상\n",
      "  1: 감_특\n",
      "  2: 감_상\n",
      "  3: 배_특\n",
      "  4: 사과_상\n",
      "  5: 사과_특\n",
      "  6: 사과_보통\n",
      "  7: 감_보통\n",
      "  8: 배_보통\n",
      "2단계 YOLOv5 학습\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLO train: 100%|██████████| 72/72 [00:01<00:00, 45.08it/s]\n",
      "YOLO val: 100%|██████████| 9/9 [00:00<00:00, 41.44it/s]\n",
      "YOLO test: 100%|██████████| 9/9 [00:00<00:00, 39.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLO 데이터셋 준비 완료: c:\\miniproject\\data정리\\processed\\preprocessed_data\\yolov5\n",
      "\n",
      " YOLOv5 학습 시작\n",
      "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov5su.pt to 'c:\\miniproject\\data정리\\processed\\results_comparison\\yolov5su.pt': 100% ━━━━━━━━━━━━ 17.7MB 10.7MB/s 1.7s1.6s<0.0s\n",
      "New https://pypi.org/project/ultralytics/8.3.227 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.225  Python-3.9.25 torch-2.7.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3060 Laptop GPU, 6144MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=c:\\miniproject\\data\\processed\\preprocessed_data\\yolov5\\data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=5, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=c:\\miniproject\\data\\processed\\results_comparison\\yolov5su.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=yolov5_freshness, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=30, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=c:\\miniproject\\data\\processed\\results_comparison, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=C:\\miniproject\\data\\processed\\results_comparison\\yolov5_freshness, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=0, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=9\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      3520  ultralytics.nn.modules.conv.Conv             [3, 32, 6, 2, 2]              \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     18816  ultralytics.nn.modules.block.C3              [64, 64, 1]                   \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    115712  ultralytics.nn.modules.block.C3              [128, 128, 2]                 \n",
      "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  6                  -1  3    625152  ultralytics.nn.modules.block.C3              [256, 256, 3]                 \n",
      "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  8                  -1  1   1182720  ultralytics.nn.modules.block.C3              [512, 512, 1]                 \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1    131584  ultralytics.nn.modules.conv.Conv             [512, 256, 1, 1]              \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    361984  ultralytics.nn.modules.block.C3              [512, 256, 1, False]          \n",
      " 14                  -1  1     33024  ultralytics.nn.modules.conv.Conv             [256, 128, 1, 1]              \n",
      " 15                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 16             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 17                  -1  1     90880  ultralytics.nn.modules.block.C3              [256, 128, 1, False]          \n",
      " 18                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 19            [-1, 14]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 20                  -1  1    296448  ultralytics.nn.modules.block.C3              [256, 256, 1, False]          \n",
      " 21                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 22            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 23                  -1  1   1182720  ultralytics.nn.modules.block.C3              [512, 512, 1, False]          \n",
      " 24        [17, 20, 23]  1   2119531  ultralytics.nn.modules.head.Detect           [9, [128, 256, 512]]          \n",
      "YOLOv5s summary: 153 layers, 9,125,675 parameters, 9,125,659 gradients, 24.1 GFLOPs\n",
      "\n",
      "Transferred 421/427 items from pretrained weights\n",
      "Freezing layer 'model.24.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 18.15.0 MB/s, size: 194.2 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\miniproject\\data정리\\processed\\preprocessed_data\\yolov5\\labels\\train... 72 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 72/72 666.4it/s 0.1s0.0s\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: C:\\miniproject\\data\\processed\\preprocessed_data\\yolov5\\labels\\train.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 14.24.0 MB/s, size: 174.9 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\miniproject\\data정리\\processed\\preprocessed_data\\yolov5\\labels\\val... 9 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 9/9 524.4it/s 0.0s\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: C:\\miniproject\\data\\processed\\preprocessed_data\\yolov5\\labels\\val.cache\n",
      "Plotting labels to C:\\miniproject\\data\\processed\\results_comparison\\yolov5_freshness\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000769, momentum=0.9) with parameter groups 69 weight(decay=0.0), 76 weight(decay=0.0005), 75 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mC:\\miniproject\\data\\processed\\results_comparison\\yolov5_freshness\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K        1/5      3.78G       1.34       4.23      1.969         28        640: 100% ━━━━━━━━━━━━ 5/5 1.3it/s 3.8s0.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.5it/s 0.3s\n",
      "                   all          9          9      0.152      0.306     0.0781     0.0608\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K        2/5      3.82G      1.254      3.864      1.907         28        640: 100% ━━━━━━━━━━━━ 5/5 1.4it/s 3.6s0.7ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.3it/s 0.3s\n",
      "                   all          9          9      0.307        0.5      0.135      0.118\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K        3/5      3.89G     0.7625      3.129      1.491         24        640: 100% ━━━━━━━━━━━━ 5/5 1.4it/s 3.5s0.7ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.8it/s 0.6s\n",
      "                   all          9          9      0.168       0.75      0.251      0.233\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K        4/5      3.91G     0.5885      2.653      1.301         29        640: 100% ━━━━━━━━━━━━ 5/5 1.5it/s 3.4s0.6ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.7it/s 0.6s\n",
      "                   all          9          9      0.197      0.745      0.413      0.374\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K        5/5      3.77G      0.541      2.432      1.249         20        640: 100% ━━━━━━━━━━━━ 5/5 1.7it/s 2.9s0.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.3it/s 0.4s\n",
      "                   all          9          9      0.353      0.675      0.412      0.367\n",
      "\n",
      "5 epochs completed in 0.006 hours.\n",
      "Optimizer stripped from C:\\miniproject\\data\\processed\\results_comparison\\yolov5_freshness\\weights\\last.pt, 18.5MB\n",
      "Optimizer stripped from C:\\miniproject\\data\\processed\\results_comparison\\yolov5_freshness\\weights\\best.pt, 18.5MB\n",
      "\n",
      "Validating C:\\miniproject\\data\\processed\\results_comparison\\yolov5_freshness\\weights\\best.pt...\n",
      "Ultralytics 8.3.225  Python-3.9.25 torch-2.7.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3060 Laptop GPU, 6144MiB)\n",
      "YOLOv5s summary (fused): 84 layers, 9,115,019 parameters, 0 gradients, 23.8 GFLOPs\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.7it/s 0.6s\n",
      "                   all          9          9      0.196      0.744      0.413      0.374\n",
      "                   _          1          1      0.168          1      0.249      0.224\n",
      "                   _          1          1          0          0     0.0905     0.0543\n",
      "                   _          1          1      0.109          1      0.142      0.128\n",
      "                  _          1          1      0.318      0.955      0.332      0.298\n",
      "                  _          1          1      0.281          1      0.995      0.895\n",
      "                 _          1          1      0.381          1      0.995      0.895\n",
      "                  _          1          1      0.311          1      0.497      0.497\n",
      "                  _          2          2          0          0          0          0\n",
      "Speed: 0.3ms preprocess, 6.6ms inference, 0.0ms loss, 43.2ms postprocess per image\n",
      "Results saved to \u001b[1mC:\\miniproject\\data\\processed\\results_comparison\\yolov5_freshness\u001b[0m\n",
      " YOLOv5 학습 완료\n",
      "3단계 EfficientDet 학습\n",
      "\n",
      " EfficientDet 학습 시작\n",
      "COCO train annotations: c:\\miniproject\\data정리\\processed\\preprocessed_data\\efficientdet\\coco_train.json\n",
      "COCO val annotations: c:\\miniproject\\data정리\\processed\\preprocessed_data\\efficientdet\\coco_val.json\n",
      "COCO test annotations: c:\\miniproject\\data정리\\processed\\preprocessed_data\\efficientdet\\coco_test.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (bn2.num_batches_tracked, bn2.bias, bn2.running_mean, bn2.running_var, bn2.weight, classifier.bias, classifier.weight, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
      "Epoch 1/30: 100%|██████████| 18/18 [00:06<00:00,  2.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train=1.9158, Val=840.9242\n",
      "Saved (Loss: 840.9242)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/30: 100%|██████████| 18/18 [00:05<00:00,  3.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train=0.8140, Val=1019.6730\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/30: 100%|██████████| 18/18 [00:05<00:00,  3.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train=0.4483, Val=123.0137\n",
      "Saved (Loss: 123.0137)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/30: 100%|██████████| 18/18 [00:05<00:00,  3.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Train=0.4087, Val=46.2192\n",
      "Saved (Loss: 46.2192)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/30: 100%|██████████| 18/18 [00:05<00:00,  3.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train=0.3818, Val=5.5214\n",
      "Saved (Loss: 5.5214)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/30: 100%|██████████| 18/18 [00:05<00:00,  3.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Train=0.3685, Val=4.9156\n",
      "Saved (Loss: 4.9156)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/30: 100%|██████████| 18/18 [00:05<00:00,  3.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Train=0.3403, Val=3.0084\n",
      "Saved (Loss: 3.0084)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/30: 100%|██████████| 18/18 [00:05<00:00,  3.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: Train=0.3206, Val=0.9012\n",
      "Saved (Loss: 0.9012)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/30: 100%|██████████| 18/18 [00:05<00:00,  3.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: Train=0.3337, Val=0.4612\n",
      "Saved (Loss: 0.4612)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/30: 100%|██████████| 18/18 [00:05<00:00,  3.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: Train=0.3316, Val=1.1575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/30: 100%|██████████| 18/18 [00:05<00:00,  3.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: Train=0.3194, Val=1.2974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/30: 100%|██████████| 18/18 [00:05<00:00,  3.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: Train=0.3311, Val=1.0910\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/30: 100%|██████████| 18/18 [00:05<00:00,  3.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: Train=0.3318, Val=0.7136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/30: 100%|██████████| 18/18 [00:05<00:00,  3.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: Train=0.2984, Val=0.6137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/30: 100%|██████████| 18/18 [00:05<00:00,  3.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: Train=0.2951, Val=0.5221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/30: 100%|██████████| 18/18 [00:05<00:00,  3.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: Train=0.2721, Val=0.6390\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/30: 100%|██████████| 18/18 [00:05<00:00,  3.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: Train=0.2698, Val=0.5284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/30: 100%|██████████| 18/18 [00:05<00:00,  3.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18: Train=0.2496, Val=0.8482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/30: 100%|██████████| 18/18 [00:05<00:00,  3.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: Train=0.2442, Val=0.7711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/30: 100%|██████████| 18/18 [00:05<00:00,  3.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: Train=0.2244, Val=1.8250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/30: 100%|██████████| 18/18 [00:05<00:00,  3.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21: Train=0.2152, Val=0.5497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/30: 100%|██████████| 18/18 [00:05<00:00,  3.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22: Train=0.1793, Val=0.5507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/30: 100%|██████████| 18/18 [00:05<00:00,  3.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23: Train=0.1810, Val=0.4794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/30: 100%|██████████| 18/18 [00:05<00:00,  3.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: Train=0.1469, Val=0.3857\n",
      "Saved (Loss: 0.3857)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/30: 100%|██████████| 18/18 [00:05<00:00,  3.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25: Train=0.1558, Val=0.4440\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/30: 100%|██████████| 18/18 [00:05<00:00,  3.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26: Train=0.1506, Val=0.4835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/30: 100%|██████████| 18/18 [00:05<00:00,  3.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27: Train=0.1431, Val=0.3585\n",
      "Saved (Loss: 0.3585)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28/30: 100%|██████████| 18/18 [00:05<00:00,  3.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28: Train=0.1336, Val=0.4411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29/30: 100%|██████████| 18/18 [00:05<00:00,  3.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: Train=0.1220, Val=0.3368\n",
      "Saved (Loss: 0.3368)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30/30: 100%|██████████| 18/18 [00:05<00:00,  3.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30: Train=0.1154, Val=0.3370\n",
      "EfficientDet 학습 완료 (Best Loss: 0.3368)\n",
      " EfficientDet 학습 곡선 저장됨: c:\\miniproject\\data정리\\processed\\results_comparison\\efficientdet_loss_curve.png\n",
      "4단계 실제 테스트 데이터로 최종 평가\n",
      "   테스트 이미지 수: 9개\n",
      "\n",
      " YOLOv5 테스트셋 평가 시작\n",
      "Ultralytics 8.3.225  Python-3.9.25 torch-2.7.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3060 Laptop GPU, 6144MiB)\n",
      "YOLOv5s summary (fused): 84 layers, 9,115,019 parameters, 0 gradients, 23.8 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 17.94.9 MB/s, size: 202.6 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\miniproject\\data정리\\processed\\preprocessed_data\\yolov5\\labels\\test... 9 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 9/9 682.1it/s 0.0s\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: C:\\miniproject\\data\\processed\\preprocessed_data\\yolov5\\labels\\test.cache\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 0.3it/s 3.5s\n",
      "                   all          9          9      0.237      0.832      0.444      0.375\n",
      "                   _          1          1      0.117          1      0.199      0.179\n",
      "                   _          1          1      0.532          1      0.995      0.697\n",
      "                   _          1          1     0.0815          1      0.199      0.129\n",
      "                  _          2          2      0.228      0.896      0.249      0.249\n",
      "                  _          1          1          0          0      0.142      0.128\n",
      "                 _          2          2      0.235          1      0.828      0.796\n",
      "                  _          1          1      0.465       0.93      0.497      0.448\n",
      "Speed: 2.3ms preprocess, 35.7ms inference, 0.0ms loss, 39.9ms postprocess per image\n",
      "Results saved to \u001b[1mC:\\miniproject\\data\\processed\\results_comparison\\yolov5_test\u001b[0m\n",
      "YOLOv5 테스트 완료\n",
      "  mAP@0.5: 0.444\n",
      "  mAP@0.5:0.95: 0.375\n",
      "  Precision: 0.237\n",
      "  Recall: 0.832\n",
      "YOLO metrics 저장: c:\\miniproject\\data정리\\processed\\results_comparison\\yolo_metrics.json\n",
      "\n",
      " EfficientDet 테스트셋 평가 시작\n",
      "\n",
      "EfficientDet COCO 평가 시작\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting on Test Set: 100%|██████████| 9/9 [00:00<00:00, 12.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.02s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.03s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.764\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.786\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.786\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.764\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.814\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.814\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.814\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.814\n",
      "EfficientDet metrics 저장: c:\\miniproject\\data정리\\processed\\results_comparison\\efficientdet_metrics.json\n",
      "\n",
      " EfficientDet Confusion Matrix 평가 시작\n",
      "\n",
      " 테스트 데이터 예측 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 9/9 [00:00<00:00, 14.65it/s]\n",
      "C:\\Users\\smart\\AppData\\Local\\Temp\\ipykernel_3300\\3296030768.py:107: RuntimeWarning: invalid value encountered in divide\n",
      "  cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Confusion Matrix 생성 중\n",
      " 정규화된 Confusion Matrix 저장: c:\\miniproject\\data정리\\processed\\results_comparison\\efficientdet_confusion_matrix_normalized.png\n",
      " 개수 Confusion Matrix 저장: c:\\miniproject\\data정리\\processed\\results_comparison\\efficientdet_confusion_matrix_count.png\n",
      "\n",
      " Classification Report:\n",
      "======================================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         배_상       0.00      0.00      0.00         1\n",
      "         감_상       0.00      0.00      0.00         1\n",
      "         배_특       0.50      1.00      0.67         1\n",
      "        사과_상       1.00      1.00      1.00         2\n",
      "        사과_특       0.50      1.00      0.67         1\n",
      "       사과_보통       1.00      0.50      0.67         2\n",
      "        감_보통       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.56         9\n",
      "   macro avg       0.43      0.50      0.43         9\n",
      "weighted avg       0.56      0.56      0.52         9\n",
      "\n",
      "\n",
      " Classification Report 저장: c:\\miniproject\\data정리\\processed\\results_comparison\\efficientdet_classification_report.txt\n",
      " 클래스별 정확도 그래프 저장: c:\\miniproject\\data정리\\processed\\results_comparison\\efficientdet_per_class_accuracy.png\n",
      "\n",
      " 전체 정확도: 0.556\n",
      " 총 테스트 샘플: 9개\n",
      " 정확히 분류된 샘플: 5개\n",
      " Confusion Matrix 데이터 저장: c:\\miniproject\\data정리\\processed\\results_comparison\\efficientdet_confusion_matrix.json\n",
      "\n",
      "EfficientDet 테스트 완료\n",
      " mAP@0.5: 0.786\n",
      " mAP@0.5:0.95: 0.764\n",
      " Precision: 0.764\n",
      " Recall: 0.814\n",
      " Overall Accuracy: 0.556\n",
      "【5단계】 결과 비교 및 시각화\n",
      "\n",
      "======================================================================\n",
      "                         실제 테스트 데이터 최종 성능 비교                          \n",
      "======================================================================\n",
      "\n",
      "Metric               YOLOv5          EfficientDet    Difference     \n",
      "----------------------------------------------------------------------\n",
      "mAP@0.5              0.444           0.786           -0.341\n",
      "mAP@0.5:0.95         0.375           0.764           -0.389\n",
      "Precision            0.237           0.764           -0.527\n",
      "Recall               0.832           0.814           +0.018\n",
      "\n",
      "======================================================================\n",
      "EfficientDet가 0.341만큼 더 높은 mAP@0.5를 달성했습니다!\n",
      "======================================================================\n",
      "\n",
      " 비교 그래프 저장: c:\\miniproject\\data정리\\processed\\results_comparison\\performance_comparison_test.png\n",
      "\n",
      " 최종 성능 비교 그래프 저장 완료 → c:\\miniproject\\data정리\\processed\\results_comparison\\final_comparison_graph.png\n",
      "모든 작업 완료!\n",
      "\n",
      " 결과 저장 위치: C:\\miniproject\\data정리\\processed\\results_comparison\n",
      "\n",
      " 생성된 파일:\n",
      "  YOLOv5 테스트: yolov5_test/\n",
      "  EfficientDet 테스트 예측: efficientdet_test_predictions/\n",
      "  성능 비교 그래프: performance_comparison_test.png\n",
      "  최종 비교 그래프: final_comparison_graph.png\n",
      "  요약 그래프: test_summary_graph.png\n",
      "  결과 JSON: final_test_results.json\n",
      "  YOLO metrics: yolo_metrics.json\n",
      "  EfficientDet metrics: efficientdet_metrics.json\n",
      "\n",
      " 데이터 구성:\n",
      "  - 학습: 72개 (원천데이터 80%)\n",
      "  - 검증: 9개 (원천데이터 20%)\n",
      "  - 테스트: 9개 (별도 실제 데이터)\n",
      "\n",
      " 최종 승자: EfficientDet\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d97aa9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf01",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.25"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
